{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96515767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#pip install opencv-python\n",
    "# Test OpenCV\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeae7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0eec8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "DIRECTORY = r\"D:\\Gesture Image Data\"\n",
    "\n",
    "CATEGORIES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68e3c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess the data\n",
    "DATA = []  #store the image and labals( 'VICTORY( 0 ) and FOOD IS YUMMY( 1 ) ) \n",
    "\n",
    "for category in CATEGORIES:\n",
    "    i=0\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        if i==10:\n",
    "            break\n",
    "        i=i+1\n",
    "        img_path = os.path.join(path, img)\n",
    "        label = CATEGORIES.index(category)\n",
    "        arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        new_arr = cv2.resize(arr, (40, 40))        #resize the image using cv2\n",
    "        DATA.append([new_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5127fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data after preprocessed how to look\n",
    "\n",
    "\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg \n",
    "# def image(path):\n",
    "#     img = mpimg.imread(path)\n",
    "\n",
    "#     # Display the image\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')  # Hide axes\n",
    "#     plt.show()\n",
    "#     img = cv2.imread( path, cv2.IMREAD_GRAYSCALE )\n",
    "#     new_arr = cv2.resize(img, (40, 40))\n",
    "#     plt.imshow(new_arr)\n",
    "#     plt.axis('off')  # Hide axes\n",
    "#     plt.show()\n",
    "#     new_arr = np.array(new_arr)\n",
    "#     new_arr = new_arr.reshape(-1, 40, 40, 1)\n",
    "    \n",
    "\n",
    "# image(r'D:\\abdulrahman\\gesturedata\\VICTORY\\2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed7cbefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[180, 179, 180, ..., 165, 163, 163],\n",
       "        [180, 180, 180, ..., 166, 164, 164],\n",
       "        [179, 179, 179, ..., 165, 164, 164],\n",
       "        ...,\n",
       "        [173, 172, 170, ..., 161, 161, 162],\n",
       "        [172, 171, 169, ..., 160, 160, 160],\n",
       "        [171, 170, 169, ..., 158, 159, 160]], dtype=uint8),\n",
       " 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e72fca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separete the inputs and labals\n",
    "INPUT = []  #   store the images in list\n",
    "LABELS = []  #   store the labals of image\n",
    "for input_labals in DATA:\n",
    "    INPUT.append(input_labals[0])\n",
    "    LABELS.append(input_labals[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69a797da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "print(len(INPUT))\n",
    "print(len(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d4c5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = np.array(INPUT) / 255.0    # for normalization because they are 255 pixel in each chanel so each pixel is bw 0 and 1\n",
    "LABELS = np.array(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7023f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(LABELS))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e3ea4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71372549, 0.70980392, 0.70588235, ..., 0.64705882, 0.64313725,\n",
       "        0.64313725],\n",
       "       [0.70980392, 0.70588235, 0.70588235, ..., 0.65098039, 0.64705882,\n",
       "        0.64705882],\n",
       "       [0.70980392, 0.70980392, 0.70980392, ..., 0.65098039, 0.65098039,\n",
       "        0.64705882],\n",
       "       ...,\n",
       "       [0.6745098 , 0.6745098 , 0.6745098 , ..., 0.65882353, 0.65882353,\n",
       "        0.6627451 ],\n",
       "       [0.67058824, 0.67058824, 0.67058824, ..., 0.65098039, 0.65882353,\n",
       "        0.6627451 ],\n",
       "       [0.67058824, 0.67058824, 0.67058824, ..., 0.65098039, 0.65882353,\n",
       "        0.65882353]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35c3ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT = INPUT.reshape(-1, 40, 40, 1)   #  only gray (1) channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff90b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc81223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define input layer with specified input shape\n",
    "input_layer = Input(shape=(40, 40, 1))\n",
    "\n",
    "# Add convolutional layer with specified parameters\n",
    "conv1 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "# Add another convolutional layer\n",
    "conv2 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before passing to dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Fully connected layers\n",
    "dense1 = Dense(256, activation='relu')(flatten)\n",
    "dense2 = Dense(128, activation='relu')(dense1)\n",
    "dense3 = Dense(64, activation='relu')(dense2)\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(26, activation='softmax')(dense3)  # 26 classes\n",
    "\n",
    "# Create model by specifying input and output layers\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4471aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with appropriate loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544d833",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb197fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - accuracy: 0.0440 - loss: 3.2575 - val_accuracy: 0.0000e+00 - val_loss: 3.5206\n",
      "Epoch 2/2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.0576 - loss: 3.1980 - val_accuracy: 0.0000e+00 - val_loss: 4.2131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f79e224f20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(INPUT,LABELS, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06723f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "def image(path):\n",
    "    img = mpimg.imread(path)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "    img = cv2.imread( path, cv2.IMREAD_GRAYSCALE )\n",
    "    new_arr = cv2.resize(img, (40, 40))\n",
    "    new_arr = np.array(new_arr)\n",
    "    new_arr = new_arr.reshape(-1, 40, 40, 1)\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "931e3fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "U\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "prediction = model.predict([image(r\"D:\\Gesture Image Pre-Processed Data\\M\\35.jpg\")])\n",
    "print(CATEGORIES[prediction.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a942481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
